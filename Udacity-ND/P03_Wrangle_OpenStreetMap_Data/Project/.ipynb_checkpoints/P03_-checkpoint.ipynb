{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wrangle OpenStreetMap Data "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Map Area"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Baltimore, MD, United State\n",
    "- I chose this city because I used to live there while I was doing my master dgree in US\n",
    "- openstreetmap : https://www.openstreetmap.org/node/671113#map=11/39.2915/-76.6114\n",
    "- I used mapzen.com (https://mapzen.com/data/metro-extracts/) to extract OSM file\n",
    "- OSM file is 443 MB after extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quick look inot our dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I went through the provided Case Study for SQL, and used it as my starting point. \n",
    "\n",
    "* using <B>mapparser.py</B> we could get tags count in our dataset\n",
    "\n",
    "```python\n",
    "def count_tags(filename):\n",
    "\ttags = {}\n",
    "\titerparse = ET.iterparse(filename)\n",
    "\tfor event, elemet in iterparse:\n",
    "\t\tif elemet.tag in tags :\n",
    "\t\t\ttags[elemet.tag] += 1\n",
    "\t\telse :\n",
    "\t\t\ttags[elemet.tag] = 1\n",
    "\treturn tags\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    tags = count_tags(oms_file)\n",
    "    print(\"Tag\", \"Count\")\n",
    "    for t, c in tags.items():\n",
    "    \tprint(t,c)\n",
    "```\n",
    "\n",
    "```\n",
    "\n",
    "| Tag        | Count  |\n",
    "|------------|--------|\n",
    "|   osm      | 1      |\n",
    "|   bounds   | 1      |\n",
    "|   way      | 250595 |\n",
    "|   nd       | 2346656|\n",
    "|   member   | 17730  |\n",
    "|   tag      | 1598118|\n",
    "|   relation | 851    |\n",
    "|   node     | 1800900|\n",
    "\n",
    "```   \n",
    "  \n",
    "  \n",
    "<br />\n",
    "<br />\n",
    "* using <B>tags.py</B> I digged deeper to find out if dataset has issues \n",
    "\n",
    "```python\n",
    "def key_type(element, keys):\n",
    "    if element.tag == \"tag\":\n",
    "        for tag in element.iter('tag'):\n",
    "            if lower.search(element.attrib['k']):\n",
    "                keys['lower'] = keys['lower'] + 1\n",
    "            elif lower_colon.search(element.attrib['k']):\n",
    "                keys['lower_colon'] = keys['lower_colon'] + 1\n",
    "            elif problemchars.search(element.attrib['k']):\n",
    "                keys['problemchars'] = keys['problemchars'] + 1\n",
    "            else:\n",
    "                keys['other'] = keys['other'] + 1\n",
    "    \n",
    "    return keys\n",
    "    \n",
    "def process_map(filename):\n",
    "    keys = {\"lower\": 0, \"lower_colon\": 0, \"problemchars\": 0, \"other\": 0}\n",
    "    for _, element in ET.iterparse(filename):\n",
    "        keys = key_type(element, keys)\n",
    "\n",
    "    return keys\n",
    "\n",
    "```\n",
    "\n",
    "```\n",
    "\n",
    "| Tag category  | Count  |\n",
    "|---------------|--------|\n",
    "|   lower       | 3361271|\n",
    "|   lower_colon | 1258410|\n",
    "|   problemchars| 2      |\n",
    "|   other       | 3579   |\n",
    "\n",
    "\n",
    "```\n",
    "\n",
    "\n",
    "\n",
    "<br />\n",
    "<br />\n",
    "* using <B>users.py</B> I found out that we have 384 in our dataset\n",
    "\n",
    "```python\n",
    "def process_map(filename):\n",
    "    users = set()\n",
    "    for _, element in ET.iterparse(filename):\n",
    "        if \"uid\" in element.attrib:\n",
    "        \tusers.add(element.attrib[\"uid\"])\n",
    "\n",
    "    return users\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problems Encountered in the Map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Abbreviation and accuracy of street names\n",
    "\n",
    "I built an auditing script <B>audit.py</B> to give a summary about how street names and a look like in my dataset. Initially, I used the provdied expected and mapping lists of street prefix :\n",
    "\n",
    "```python\n",
    "expected = [\"Street\", \"Avenue\", \"Boulevard\", \"Drive\", \"Court\", \"Place\", \"Square\", \"Lane\", \"Road\", \n",
    "            \"Trail\", \"Parkway\", \"Commons\"]\n",
    "mapping = { \"St\": \"Street\",\n",
    "            \"St.\": \"Street\",\n",
    "            \"Ave\" : \"Avenue\",\n",
    "            }\n",
    "\n",
    "def audit_street_type(street_types, street_name):\n",
    "    m = street_type_re.search(street_name)\n",
    "    if m:\n",
    "        street_type = m.group()\n",
    "        if street_type not in expected:\n",
    "            street_types[street_type].add(street_name)\n",
    "\n",
    "def is_street_name(elem):\n",
    "    return (elem.attrib['k'] == \"addr:street\")\n",
    "\n",
    "def audit_street(osmfile):\n",
    "    osm_file = open(osmfile, \"r\")\n",
    "    street_types = defaultdict(set)\n",
    "    for event, elem in ET.iterparse(osm_file, events=(\"start\",)):\n",
    "\n",
    "        if elem.tag == \"node\" or elem.tag == \"way\":\n",
    "            for tag in elem.iter(\"tag\"):\n",
    "                if is_street_name(tag):\n",
    "                    audit_street_type(street_types, tag.attrib['v'])\n",
    "    osm_file.close()\n",
    "    return street_types\n",
    "\n",
    "```\n",
    "\n",
    "<br />\n",
    "<br />\n",
    "Running my audit script, I got below list of street names grouped by prefix :\n",
    "```\n",
    "Kerneway {'Kerneway'}\n",
    "Strand {'The Strand'}\n",
    "Mews {'Foundry Mews', 'Balmar Mews', 'Station North Mews'}\n",
    "Circle {'Ryerson Circle', 'Songbird Circle', 'Prospect Circle', 'Dockside Circle', 'Carling Circle', 'Hazelwood\n",
    "Circle', 'Lakebrook Circle', 'Hopkins Bayview Circle', 'McCollough Circle', 'Alameda Circle', 'Park Circle', 'South Edgecombe Circle', 'Monroe Circle', 'Inner Circle', 'Palo Circle', 'Henry G Parks Jr Circle', 'Villager Circle', 'North Edgecombe Circle'}\n",
    "Townway {'Townway'}\n",
    "Center {'Freeport Center'}\n",
    "Freeway {'Freeway'}\n",
    "East {'Lighthouse Point East'}\n",
    "Sisson {'28th & Sisson'}\n",
    "Ave {'Guilford Ave', 'Maryland Ave', 'Eastern Ave'}\n",
    "Way {'Ardmore Way', 'South Twin Circle Way', 'West Cherry Blossom Way', 'Islamic Way', 'Raintree Way', 'Eric Shaefer Way', 'Waxter Way', 'Violet Hill White Way', 'Lodestone Way', 'Furley Way', 'Moravia Run Way', 'Conant Way', 'Grape Vine Way', 'Twin Circle Way', 'Green Fern Way', 'Constellation Way', 'Denview Way', 'Frailey Way', 'Whetstone Way', 'North Twin Circle Way', 'Pubped Way', 'Oak Leaf Way', 'Judith Way', 'Springlake Way', 'Anna Park Way'}\n",
    "Seamon-alley-potee {'Seamon-alley-potee'}\n",
    "Alley {'Shad Alley', 'Stoddard Alley', 'Hubbard Alley', 'Chalk Alley', 'Pothouse Alley', 'Lotus Alley', 'Slemmers Alley', 'Bauernschmidt Alley', 'Hall Alley', 'Ten Pin Alley', 'Bourke Alley', 'Hargrove Alley', 'Welcome Alley', 'Low Alley'}\n",
    "Crossing {'Saint Clair Crossing Crossing', 'Saint Clair Crossing'}\n",
    "Westway {'Westway'}\n",
    "Broadway {'North Broadway', 'South Broadway'}\n",
    "Hwy {'Broening Hwy'}\n",
    "st. {'W. Pratt st.'}\n",
    "Fallsway {'Fallsway'}\n",
    "Point {'East Lighthouse Point'}\n",
    "Highway {'Broening Highway', 'Key Highway', 'Governor Ritchie Highway', 'East Key Highway', 'Edison Highway', 'Pulaski Highway'}\n",
    "Off {\"O'Donnell Street Cut Off\"}\n",
    "St. {'N. Charles St.'}\n",
    "Run {'Friar Field Run'}\n",
    "Northway {'Northway', 'Loyola Northway'}\n",
    "Plaza {'Hopkins Plaza', 'Constellation Plaza'}\n",
    "735 {'Guilford Avenue # 735'}\n",
    "Mall {'Oldtown Mall'}\n",
    "Landing {'Pilgrim Landing'}\n",
    "Pass {'Fredhilton Pass', 'Poncabird Pass'}\n",
    "Alameda {'The Alameda'}\n",
    "Juneway {'Juneway'}\n",
    "Walk {'Harbor Island Walk', 'Cambridge Walk'}\n",
    "Eastway {'Eastway'}\n",
    "Greenway {'Greenway'}\n",
    "Kinsway {'Kinsway'}\n",
    "Washington-carroll {'Washington-carroll'}\n",
    "Gardens {'Goodwood Gardens'}\n",
    "Terrace {'Clifton Park Terrace', 'Mount Royal Terrace', 'Gilman Terrace', 'Parkview Terrace', 'Adelle Terrace','Homewood Terrace', 'Staab Terrace', 'Falls Road Terrace', 'Elsa Terrace', 'Edgar Terrace', 'Leeds Terrace','Montebello Terrace', 'Guilford Terrace', 'Poplar Terrace', 'Rosecroft Terrace', 'Lake Montebello Terrace', 'Rose Hill Terrace', 'Chelsea Terrace', 'Auchentoroly Terrace', 'Park Heights Terrace', 'Latrobe Park Terrace', 'Iona Terrace'}\n",
    "Green {'Linden Green'}\n",
    "Nelway {'Nelway'}\n",
    "Southway {'Southway', 'Homeland Southway', 'Loyola Southway'}\n",
    "st {'north kresson st'}\n",
    "```\n",
    "<br />\n",
    "After ding some search and reading through Wikipedia and multiple resources I idetified couple of above prefix groups that need to be added to my expected list, and mapping list too .\n",
    "\n",
    "Updating our expected and mapping lists :\n",
    "```python\n",
    "expected = [\"Street\", \"Avenue\", \"Boulevard\", \"Drive\", \"Court\", \"Place\", \"Square\", \"Lane\", \"Road\", \n",
    "            \"Trail\", \"Parkway\", \"Commons\",\"Highway\", \"Alley\", \"Terrace\", \"Broadway\", \"Pass\", \"Plaza\", \n",
    "            \"Circle\", \"Way\", \"Walk\", \"Alameda\", \"Northway\", \"Fallsway\", \"Freeway\", \"Kerneway\", \"Center\",\n",
    "            \"East\", \"Westway\", \"Kinsway\", \"Run\", \"Strand\", \"Gardens\", \"Juneway\", \"Off\", \"Greenway\", \n",
    "            \"Southway\", \"Eastway\", \"Mews\", \"Townway\"]\n",
    "\n",
    "mapping = { \"St\": \"Street\",\n",
    "            \"st\" : \"Street\",\n",
    "            \"St.\": \"Street\",\n",
    "            \"st.\": \"Street\",\n",
    "            \"Ave\" : \"Avenue\",\n",
    "            \"Hwy\" : \"Highway\"\n",
    "            }\n",
    "```\n",
    "\n",
    "Now, I'll run my audit script again for further investigation. Below is mt final list that contains street names that need to be handled :\n",
    "\n",
    "```\n",
    "Landing {'Pilgrim Landing'}\n",
    "Ave {'Maryland Ave', 'Guilford Ave', 'Eastern Ave'}\n",
    "Seamon-alley-potee {'Seamon-alley-potee'}\n",
    "Mall {'Oldtown Mall'}\n",
    "Green {'Linden Green'}\n",
    "Crossing {'Saint Clair Crossing', 'Saint Clair Crossing Crossing'}\n",
    "st {'north kresson st'}\n",
    "735 {'Guilford Avenue # 735'}\n",
    "Washington-carroll {'Washington-carroll'}\n",
    "Nelway {'Nelway'}\n",
    "Point {'East Lighthouse Point'}\n",
    "Hwy {'Broening Hwy'}\n",
    "st. {'W. Pratt st.'}\n",
    "Sisson {'28th & Sisson'}\n",
    "St. {'N. Charles St.'}\n",
    "```\n",
    "\n",
    "Based on above list, I've built a function to update street names and prefix as required. For some streets in my issues list I did manual cleaning as it's only my option and as I learned too that data cleaning could require manual action .\n",
    "```python\n",
    "def update_name(name, mapping):\n",
    "    # handle incorrect street names - Manually\n",
    "    if name == \"Saint Clair Crossing Crossing\" or name == \"Saint Clair Crossing\":\n",
    "        return \"Saint Clair Crossing\"\n",
    "    elif name == \"Oldtown Mall\" :\n",
    "        return \"Oldtown Mall\"\n",
    "    elif name == \"East Lighthouse Point\" :\n",
    "        return \"Lighthouse Point East\"\n",
    "    elif name == \"28th & Sisson\" :\n",
    "        return \"W 28th Street & Sisson Street\"\n",
    "    elif name == \"Nelway\" :\n",
    "        return \"Nelway Avenue\"\n",
    "    elif name == \"Pilgrim Landing\" :\n",
    "        return \"Pilgrim Road\"\n",
    "    elif name == \"Guilford Avenue # 735\" :\n",
    "        return \"735 Guilford Avenue\"\n",
    "    elif name == \"Linden Green\" :\n",
    "        return \"Linden Green\"\n",
    "    elif name == \"Seamon-alley-potee\" or name == \"Washington-carroll\" :\n",
    "        return \"Unkown street name\"\n",
    "    else :\n",
    "        pass\n",
    "\n",
    "    # handle correct street names with inaccurate prefex\n",
    "    name = name.split(' ')\n",
    "    st_type = name[-1]\n",
    "\n",
    "    if st_type in mapping:\n",
    "        name[-1] = mapping[st_type]\n",
    "        name = ' '.join(name)\n",
    "        return name\n",
    "    else:\n",
    "        return  ' '.join(name)\n",
    "```\n",
    "\n",
    "The result :\n",
    "```\n",
    "W. Pratt st. => W. Pratt Street\n",
    "Oldtown Mall => Oldtown Mall\n",
    "Saint Clair Crossing Crossing => Saint Clair Crossing\n",
    "Saint Clair Crossing => Saint Clair Crossing\n",
    "Pilgrim Landing => Pilgrim Road\n",
    "Guilford Ave => Guilford Avenue\n",
    "Eastern Ave => Eastern Avenue\n",
    "Maryland Ave => Maryland Avenue\n",
    "Guilford Avenue # 735 => 735 Guilford Avenue\n",
    "28th & Sisson => W 28th Street & Sisson Street\n",
    "Seamon-alley-potee => Unkown street name\n",
    "Broening Hwy => Broening Highway\n",
    "N. Charles St. => N. Charles Street\n",
    "East Lighthouse Point => Lighthouse Point East\n",
    "Washington-carroll => Unkown street name\n",
    "north kresson st => north kresson Street\n",
    "Linden Green => Linden Green\n",
    "Nelway => Nelway Avenue\n",
    "```\n",
    "<br />\n",
    "<br />\n",
    "\n",
    "### Pose codes accuracy "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, I audit post codes to ansure that all post codes in our dataset follow US post code standard (5 digits or 5 digits +4). For example : 21212 or 21212-9999. Also, post codes must be within Baltimore, MD post codes range (21201, 21299).\n",
    "```python\n",
    "def audit_postcode(osmfile):\n",
    "    osm_file = open(osmfile, \"r\")\n",
    "    post_codes = set()\n",
    "    for event, elem in ET.iterparse(osm_file, events=(\"start\",)):\n",
    "\n",
    "        if elem.tag == \"node\" or elem.tag == \"way\":\n",
    "            for tag in elem.iter(\"tag\"):\n",
    "                if tag.attrib['k'] == \"addr:postcode\":\n",
    "                    if (not post_code_re.match(tag.attrib['v'])) or \n",
    "                    (int(tag.attrib['v']) not in range(21201, 21299)):\n",
    "                        post_codes.add(str(tag.attrib['v']))\n",
    "    osm_file.close()\n",
    "    return post_codes\n",
    "```\n",
    "\n",
    "Below post codes did not meet the requirements :\n",
    "```\n",
    "20002\n",
    "21209;21230\n",
    "01239\n",
    "21090\n",
    "```\n",
    "<br />\n",
    "<br />\n",
    "\n",
    "After some consideration, I've decided to replace inaccurate post codes with 00000\n",
    "```python\n",
    "def update_postcode(post_code):\n",
    "    if post_code in ('21090', '20002', '01239','21209;21230') :\n",
    "        return '00000'\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I've prepared <B>data.py</B> to clean the data then produces the required CSV files.\n",
    " ```python\n",
    " def shape_element(element, node_attr_fields=NODE_FIELDS, way_attr_fields=WAY_FIELDS,\n",
    "                  problem_chars=PROBLEMCHARS, default_tag_type='regular'):\n",
    "    \"\"\"Clean and shape node or way XML element to Python dict\"\"\"\n",
    "\n",
    "    node_attribs = {}\n",
    "    way_attribs = {}\n",
    "    way_nodes = []\n",
    "    tags = []  # Handle secondary tags the same way for both node and way elements\n",
    "\n",
    "\n",
    "    # NODE element\n",
    "    if element.tag == 'node':\n",
    "      for attribute in element.attrib:\n",
    "        if attribute in NODE_FIELDS:\n",
    "          node_attribs[attribute] = element.attrib[attribute]\n",
    "\n",
    "      for tag in element :\n",
    "        node_tags = {}\n",
    "        if LOWER_COLON.match(tag.attrib['k']) :\n",
    "          node_tags['id'] = element.attrib['id']\n",
    "          node_tags['key'] = tag.attrib['k'].split(':',1)[1]\n",
    "\n",
    "          if tag.attrib['k'] == \"addr:street\":\n",
    "            node_tags['value'] = audit.update_name(tag.attrib['v'], audit.mapping)\n",
    "          else :\n",
    "            node_tags['value'] = tag.attrib['v']\n",
    "\n",
    "          if tag.attrib['k'] == \"addr:postcode\":\n",
    "            node_tags['value'] = audit.update_postcode(tag.attrib['v'])\n",
    "          else :\n",
    "            node_tags['value'] = tag.attrib['v']\n",
    "\n",
    "\n",
    "\n",
    "          node_tags['type'] = tag.attrib['k'].split(':',1)[0]\n",
    "          tags.append(node_tags)\n",
    "\n",
    "        elif PROBLEMCHARS.match(tag.attrib['k']) :\n",
    "          continue\n",
    "\n",
    "        else :\n",
    "          node_tags['id'] = element.attrib['id']\n",
    "          node_tags['key'] = tag.attrib['k']\n",
    "          node_tags['value'] = tag.attrib['v']\n",
    "          node_tags['type'] = default_tag_type\n",
    "          tags.append(node_tags)\n",
    "\n",
    "      return {'node': node_attribs, 'node_tags': tags}\n",
    "\n",
    "    # WAY element\n",
    "    elif element.tag == 'way':\n",
    "      for attribute in element.attrib:\n",
    "        if attribute in WAY_FIELDS:\n",
    "          way_attribs[attribute] = element.attrib[attribute]\n",
    "\n",
    "      nd_pos = 1\n",
    "\n",
    "      for child in element:\n",
    "        way_node = {}\n",
    "        way_tag = {}\n",
    "        if child.tag == 'nd' :\n",
    "          way_node['id'] = element.attrib['id']\n",
    "          way_node['node_id'] = child.attrib['ref']\n",
    "          way_node['position'] = nd_pos\n",
    "          nd_pos += 1\n",
    "          way_nodes.append(way_node)\n",
    "          \n",
    "\n",
    "        elif child.tag == 'tag' :\n",
    "          if LOWER_COLON.match(child.attrib['k']):\n",
    "            way_tag['id'] = element.attrib['id']\n",
    "            way_tag['key'] = child.attrib['k'].split(':',1)[1]\n",
    "\n",
    "            if child.attrib['k'] == \"addr:street\":\n",
    "              way_tag['value'] = audit.update_name(child.attrib['v'], audit.mapping)\n",
    "            else :\n",
    "              way_tag['value'] = child.attrib['v']\n",
    "\n",
    "            way_tag['type'] = child.attrib['k'].split(':',1)[0]\n",
    "            tags.append(way_tag)\n",
    "\n",
    "          elif PROBLEMCHARS.match(child.attrib['k']):\n",
    "            continue\n",
    "\n",
    "          else :\n",
    "            way_tag['id'] = element.attrib['id']\n",
    "            way_tag['key'] = child.attrib['k']\n",
    "            way_tag['value'] = child.attrib['v']\n",
    "            way_tag['type'] = default_tag_type\n",
    "            tags.append(way_tag)\n",
    "\n",
    "      return {'way': way_attribs, 'way_nodes': way_nodes, 'way_tags': tags}\n",
    " \n",
    " ```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load cleaned data (csv) inot Sqlite"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- I used the provided database schema to create the tables\n",
    "- I took advantage of built in sqlite commands to import csv files in database\n",
    "- ** for some reasons I couldn't get sqlite to work with python on my machine **\n",
    "\n",
    "<B>Sqlite commands </B>\n",
    "```\n",
    ".mode csv\n",
    ".import xxxx/nodes.csv nodes\n",
    ".import xxxx/nodes_tags.csv nodes_tags\n",
    "\n",
    ".import xxxx/ways.csv ways\n",
    ".import xxxx/ways_nodes.csv ways_nodes\n",
    ".import xxxx/ways_tags.csv ways_tags\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Overview and Additional Ideas\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This section contains basic statistics about the dataset, sqlite queries used to gather them, and some additional ideas about the data in context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
